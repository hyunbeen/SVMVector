4월 1째주 연구노트 - SVM 특성2

비선형 특징들에 대한 classification
 SVM의 목표는 고차원의 특징공간에서에서 데이터들을 잘 구별할 수 있는 초평면을 학습을 통하여 결정을 하며,연산량 관점에서 효율적으로 구할 수 있는 방법을
 제공하는 것이다. 이미 선형적으로 분리가 가능한 특징들에 대하여서는 알아 보았다.

선형적으로 도저히 구별 하기 어려운 특징들에 대해서는 다른 방법이 필요하다. 구별이 가능한 방향으로 사상을 시키면 원래는 선형적으로 구별이 불가능한 
특징들도 새로운 공간에서는 구별이 가능하다.

Kernel Trick
2차원 평면상에서 동그라미와 엑스가 있는 경우를 생각해보자. 이를 구별하려면 타원을 만들어 구별할 수가 있다. 하지만 이것을 매핑함수를 통해 3차원 평면으로
변환시킬 수가 있다면 선형적으로 구별이 가능하다. 이렇게 매핑을 통해 고차원으로 변환시킨 후 선형적으로 구별이 가능하도록 하는 방법을 커널트릭이라고
부르고, 그때 사용하는 함수를 커널 함수라고 부른다.

SVM은 특징 벡터에 주목을 하였지만, 특징 벡터를 사용하는 것보다는 커널함수를 사용하는 편이 훨씬 간결하게 표현이 가능하고, 비선형적인 특징들도 구별이
가능하기 때문에 커널트릭이 고안된 것이다.

커널함수를 사용할 때의 이점은 최적화에 관련된 복잡도가 새로 옮겨진 특징 공간의 복잡도에 영향을 받는 것이 아니라 이저 입력 공간의 영향을 받는다는 
점이기 때문에, 설사 매핑을 통해 무한대의 공간으로 변환이 된다고 할지라도 최적화에 문제가 없다.
최적화에는 선형적인 경우와 마찬가지로 라그랑주 곱셈기 방법을 사용하면 되지만, 이부분은 수식적으로 복잡한 부분이 있다. 
커널함수의 종류에는 polynomial kernel, gaussian kernel, sigmoid kernel, kernels for sets , spectrum kernel for strings 등이 있다.
